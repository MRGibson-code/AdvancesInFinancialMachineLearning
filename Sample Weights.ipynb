{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimating the uniqueness of a label for concurrent returns\n",
    "\n",
    "#finding overlapping events\n",
    "def mpNumCoEvents(closeIdx, t1, molecule):\n",
    "    '''Compute the number of concurrent events per bar.\n",
    "    +molecule[0] is the date of the first event on which the weight will be computed\n",
    "    +molecule[-1] is the date of the last event on which the weight will be computed \n",
    "    any event that starts before t1[molecule].max() impacts the count'''\n",
    "    \n",
    "    # 1) find events that span the period [molecule[0], molecule[-1]]\n",
    "    t1 = t1.fillna(closeIdx[-1]) #unclosed events still msut impact other weights\n",
    "    t1 = t1[t1>=molecule[0]] #events that end at or after molecule[0]\n",
    "    t1 = tl.loc[:t1[molecule].max()] # events that start at or before t1[molecule].max()\n",
    "    \n",
    "    #count events spanning a bar\n",
    "    iloc = closeIdx.searchsorted(np.array([t1.index[0], t1.max()]))\n",
    "    count = pd.Series(0, index=closeIdx[iloc[0]:iloc[1]+1])\n",
    "    for tIn, tOut in t1.iteritems():\n",
    "        count.loc[tIn:tOut]+=1.\n",
    "    return count.loc[molecule[0]:t1[molecule].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpSampleTW(t1, numCoEvents, molecule):\n",
    "    #derive average uniqueness over the event's lifespan\n",
    "    wght = pd.Series(index=molecule)\n",
    "    for tIn, tOut in t1.loc[wght.index].iteritems():\n",
    "        wght.loc[tIn]=(1./numCoEvents.loc[tIn:tOut]).mean()\n",
    "    return wght \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using sequential bootstrapping to draw samples by likelihood of uniqueness, thus creating a sampling closer to IID \n",
    "#than using standard bootstrapping on a dataset with overlapping features\n",
    "\n",
    "#build an indicator matrix \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "def getIndMatrix(barIx, t1):\n",
    "    indM = pd.DataFrame(0, index=barIx, columns= range(t1.shape[0]))\n",
    "    for i, (t0, t1) in enumerate(t1.iteritems()):\n",
    "        indM.loc[t0:t1, i] = 1\n",
    "    return indM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgUniqueness(indM):\n",
    "    #Average Uniqueness from indicator matrix\n",
    "    c = indM.sum(axis=1) #concurrency\n",
    "    u = indM.div(c, axis=0) # uniqueness\n",
    "    avgU = u[u>0].mean() # avg u\n",
    "    return avgU\n",
    "\n",
    "def seqBootstrap(indM, sLength=None):\n",
    "    #generate a sample via sequential bootstrap\n",
    "    if sLength is None: \n",
    "        sLength = indM.shape[1]\n",
    "    phi = []\n",
    "    while len(phi)<sLength:\n",
    "        avgU = pd.Series()\n",
    "        for i in indM:\n",
    "            indM_ = indM[phi+[i]] #reduce indM\n",
    "            avgU.loc[i] = getAvgUniqueness(indM_).iloc[-1]\n",
    "        prob = avgU/avgU.sum() #draw prob\n",
    "        phi+=[np.random.choice(indM.columns, p=prob)]\n",
    "    return phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 2]\n",
      "Standard Uniqueness: 0.6666666666666666\n",
      "Sequential Uniqueness: 0.8611111111111112\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    t1 = pd.Series([2,3,5], index=[0,2,4]) # t0, t1 for each feature obs\n",
    "    barIx = range(t1.max()+1) #index of bars\n",
    "    indM = getIndMatrix(barIx, t1)\n",
    "    phi = np.random.choice(indM.columns,size=indM.shape[1])\n",
    "    print(phi)\n",
    "    print('Standard Uniqueness:', getAvgUniqueness(indM[phi]).mean())\n",
    "    phi=seqBootstrap(indM)\n",
    "    print('Sequential Uniqueness:', getAvgUniqueness(indM[phi]).mean())\n",
    "    return\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monte carlo experiment \n",
    "def getRndT1(numObs, numBars, maxH):\n",
    "    #random t series\n",
    "    t1 = pd.Series()\n",
    "    for i in range(numObs):\n",
    "        ix = np.random.randint(0,numBars)\n",
    "        val= ix + np.random.randint(1,maxH)\n",
    "        t1.loc[ix] = val\n",
    "    return t1.sort_index()\n",
    "\n",
    "def auxMC(numObs,numBars,maxH):\n",
    "    #parallelized auxiliary function\n",
    "    t1 = getRndT1(numObs, numBars, maxH)\n",
    "    barIx = range(t1.max() + 1)\n",
    "    indM = getIndMatrix(barIx, t1)\n",
    "    phi = np.random.choice(indM.columns,size=indM.shape[1])\n",
    "    stdU = getAvgUniqueness(indM[phi]).mean()\n",
    "    phi = seqBootstrap(indM)\n",
    "    seqU = getAvgUniqueness(indM[phi]).mean()\n",
    "    return {'stdU': stdU, 'seqU': seqU}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "import datetime as dt\n",
    "import sys\n",
    "def expandCall(kargs):\n",
    "    #expand the arguments of a callback function \n",
    "    func = kargs['func']\n",
    "    del kargs['func']\n",
    "    out = func(**kargs)\n",
    "    return out\n",
    "\n",
    "def processJobs_(jobs):\n",
    "    #run jobs sequentially. for debugging\n",
    "    out=[]\n",
    "    for job in jobs:\n",
    "        out_=expandCall(job)\n",
    "        out.append(out_)\n",
    "    return out\n",
    "\n",
    "def reportProgress(jobNum, numJobs, time0, task):\n",
    "    #report progress as asynch jobs are completed\n",
    "    msg = [float(jobNum)/numJobs,(time.time()-time0)/60.]\n",
    "    msg.append(msg[1] * (1/msg[0]-1))\n",
    "    timeStamp = str(dt.datetime.fromtimestamp(time.time()))\n",
    "    msg = timeStamp + ' ' + str(round(msg[0]*100,2)) + '% ' + task + 'done after ' + str(round(msg[1],2)) + ' minutes. Remianing ' + str(round(msg[2],2)) + 'minutes.'\n",
    "    if jobNum<numJobs: \n",
    "        sys.stderr.write(msg+'\\r')\n",
    "    else:\n",
    "        sys.stderr.write(msg + '\\n')\n",
    "    return\n",
    "\n",
    "def processJobs(jobs, task=None, numThreads=24):\n",
    "    #run in parallel\n",
    "    #jobs must contain a 'func' callback, for expandCall\n",
    "    if task is None: \n",
    "        task = jobs[0]['func'].__name__\n",
    "    pool = mp.Pool(processes=numThreads)\n",
    "    outputs, out, time0 = pool.imap_unordered(expandCall, jobs), [], time.time()\n",
    "    #process asynch output, report progress \n",
    "    for i, out_ in enumerate(outputs, 1): \n",
    "        out.append(out_)\n",
    "        reportProgress(i, len(jobs), time0, task)\n",
    "    pool.close();pool.join() #prevent memory leaks\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-24 13:47:17.294702 100.0% auxMCdone after 1116.9 minutes. Remianing 0.0minutes.....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 seqU            stdU\n",
      "count  1000000.000000  1000000.000000\n",
      "mean         0.693431        0.607656\n",
      "std          0.092250        0.100507\n",
      "min          0.301562        0.200000\n",
      "25%          0.628333        0.541667\n",
      "50%          0.700000        0.600000\n",
      "75%          0.761667        0.672222\n",
      "max          1.000000        1.000000\n"
     ]
    }
   ],
   "source": [
    "def mainMC(numObs=10, numBars=100, maxH=5, numIters=1E6, numThreads=24):\n",
    "    #monte carlo experiments\n",
    "    jobs = []\n",
    "    for i in range(int(numIters)):\n",
    "        job = {'func':auxMC,'numObs': numObs, 'numBars': numBars, 'maxH': maxH}\n",
    "        jobs.append(job)\n",
    "    if numThreads==1:\n",
    "        out = processJobs_(jobs)\n",
    "    else:\n",
    "        out = processJobs(jobs, numThreads=numThreads)\n",
    "    print(pd.DataFrame(out).describe())\n",
    "    return\n",
    "\n",
    "mainMC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determination of sample weight by absolute return attribution \n",
    "def mpSampleW(t1, numCoEvents, close, molecule):\n",
    "    #derive sample weight by return attribution \n",
    "    ret = np.log(close).diff() #log-returns, so that they are additive\n",
    "    wght = pd.Series(index=molecule)\n",
    "    for tIn, tOut in t1.loc[wght.index].iteritems():\n",
    "        wght.loc[tIn] = (ret.loc[tIn:tOut]/numCoEvents.loc[tIn:tOut]).sum()\n",
    "    return wght.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeDecay(tW, clfLastW=1.):\n",
    "    #apply piecewise linear decay to observed uniqueness\n",
    "    #newest observation gets weight 1, oldest obs gets weight=clfLastW\n",
    "    clfW = tW.sort_index().cumsum()\n",
    "    if clfLastW>=0:\n",
    "        slope=(1.-clfLastW)/clfW.iloc[-1]\n",
    "    else:\n",
    "        slope = 1./((clfLastW+1)*clfW.iloc[-1])\n",
    "    const = 1.-slope*clfW.iloc[-1]\n",
    "    clfW=const+slope*clfW\n",
    "    clfW[clfW<0]=0\n",
    "    print(const, slope)\n",
    "    return clfW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
